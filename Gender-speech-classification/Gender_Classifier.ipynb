{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library to read input file\n",
    "import pandas as pd\n",
    "#For math operations\n",
    "import numpy as np\n",
    "# Used for splitting training data into validation and training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Used for making TF-IDF vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#used for computing precision_recall_fscore\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#used for computing accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Compute F1-score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Compute Precision \n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#Computes Recall\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# NLTK lib for word tokenization and other pre-processing\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize,WordNetLemmatizer\n",
    "\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>character</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Someone had fun.</td>\n",
       "      <td>SEAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's no problem, honestly. Go on, go and open ...</td>\n",
       "      <td>SHIRLEY</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last night was better than ever. What's all th...</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have you checked the answerphone?  Any calls?</td>\n",
       "      <td>IAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oscar's asleep.</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text character  gender\n",
       "0                                   Someone had fun.      SEAN    male\n",
       "1  It's no problem, honestly. Go on, go and open ...   SHIRLEY  female\n",
       "2  Last night was better than ever. What's all th...       MAX    male\n",
       "3      Have you checked the answerphone?  Any calls?       IAN    male\n",
       "4                                    Oscar's asleep.       MAX    male"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading trainingData file\n",
    "data = pd.read_csv('training.csv',header=None, names=['text','character','gender'])\n",
    "\n",
    "#Showing first 5 values of the training data file\n",
    "data.head()\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRE-PROCESSING\n",
    "stoplist = stopwords.words('english')\n",
    "#lemmatizes \n",
    "def lem_message(text):\n",
    "    temp=[]\n",
    "    text = text.split()\n",
    "    wl=WordNetLemmatizer()\n",
    "    for i in text:\n",
    "        temp.append(wl.lemmatize(i,pos='v'))\n",
    "    return \" \".join(temp)\n",
    "\n",
    "#this function removes stopwords\n",
    "def remove_stopwords(text,stoplist):\n",
    "    temp=[]\n",
    "#     print(text)\n",
    "#     print (len(text))\n",
    "    text = text.split()\n",
    "    for i in range (len(text)):\n",
    "        if text[i] not in stoplist:\n",
    "            temp.append(text[i])\n",
    "    return \" \".join(temp)\n",
    "\n",
    "import string\n",
    "x = string.punctuation\n",
    "for i in range (data.shape[0]):\n",
    "    data[\"text\"].iloc[i] = re.sub('['+x+']' ,'',str(data[\"text\"].iloc[i])) #thi removes special chars use this only :p for every sentence in train and test\n",
    "    data[\"text\"].iloc[i] = lem_message(str(data[\"text\"].iloc[i]))\n",
    "    data[\"text\"].iloc[i] = remove_stopwords(data[\"text\"].iloc[i],stoplist)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[\"text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10113, 39564)\n"
     ]
    }
   ],
   "source": [
    "#pre-processing text/dialouges \n",
    "data['text']=data['text'].str.lower() # lower case\n",
    "corpus=data['text'].values.astype('U') #went through the dat aand gave \n",
    "\n",
    "# Making tf-idf vector of Text data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2)) #First word cant be bigram\n",
    "#vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "\n",
    "#Vocabulory\n",
    "featureNames=vectorizer.get_feature_names()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    " \n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "# selecting gender column as class label. Ignoring character filed \n",
    "Y= labelencoder_Y.fit_transform(data.gender)\n",
    "\n",
    "#splitting trining data, so that parameters can be fine tuned on 33% validation data\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function does evaluation\n",
    "\n",
    "def evaluate(y_test,y_pred,algoText='Random Forest (Baseline-1)'):\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('Results of  ',algoText)\n",
    "\n",
    "    print('------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    print('Accuracy    ',accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print('Recall      ',recall_score(y_test, y_pred))\n",
    "    \n",
    "    print('Precision   ',precision_score(y_test,y_pred))\n",
    "\n",
    "    print('F1-Score    ',f1_score(y_test,y_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   Random Forest (Baseline-1) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.5554224086279209\n",
      "Recall       0.5509723040659988\n",
      "Precision    0.5642727821363911\n",
      "F1-Score     0.5575432319618366\n"
     ]
    }
   ],
   "source": [
    "#applying random Forest algorithm\n",
    "\n",
    "clfRF = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "clfRF.fit(X_train, y_train) \n",
    "y_pred=clfRF.predict(X_test)\n",
    "evaluate(y_test,y_pred,'Random Forest (Baseline-1) on splitted_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "------------------------------------------------------------------\n",
      "Results of   SVM (Baseline-2) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.4919113241461953\n",
      "Recall       0.012374779021803181\n",
      "Precision    0.5121951219512195\n",
      "F1-Score     0.024165707710011506\n"
     ]
    }
   ],
   "source": [
    "#Apply linear SVM algorithm\n",
    "\n",
    "clfSVM=SVC(gamma='auto',kernel='linear', C = 0.05)\n",
    "clfSVM.fit(X_train, y_train) \n",
    "y_pred=clfSVM.predict(X_test)\n",
    "print (y_pred)\n",
    "evaluate(y_test,y_pred,'SVM (Baseline-2) on splitted_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading testing data by using Pandas Library\n",
    "\n",
    "#TEST DATA WITHOUT POS TAGS----------------------------------\n",
    "testData = pd.read_csv('test.csv',header=None, names=['character','text','gender'], dtype=str)\n",
    "\n",
    "testData.head()\n",
    "\n",
    "#PRE-PROCESSING------------------------------\n",
    "stoplist = stopwords.words('english')\n",
    "#lemmatizes \n",
    "def lem_message(text):\n",
    "    temp=[]\n",
    "    text = text.split()\n",
    "    wl=WordNetLemmatizer()\n",
    "    for i in text:\n",
    "        temp.append(wl.lemmatize(i,pos='v'))\n",
    "    return \" \".join(temp)\n",
    "\n",
    "#this function removes stopwords\n",
    "def remove_stopwords(text,stoplist):\n",
    "    temp=[]\n",
    "#     print(text)\n",
    "#     print (len(text))\n",
    "    text = text.split()\n",
    "    for i in range (len(text)):\n",
    "        if text[i] not in stoplist:\n",
    "            temp.append(text[i])\n",
    "    return \" \".join(temp)\n",
    "\n",
    "import string\n",
    "x = string.punctuation\n",
    "for i in range (data.shape[0]):\n",
    "    data[\"text\"].iloc[i] = re.sub('['+x+']' ,'',str(data[\"text\"].iloc[i])) #thi removes special chars use this only :p for every sentence in train and test\n",
    "    data[\"text\"].iloc[i] = lem_message(str(data[\"text\"].iloc[i]))\n",
    "    data[\"text\"].iloc[i] = remove_stopwords(data[\"text\"].iloc[i],stoplist)\n",
    "    \n",
    "#------------------------------------------------\n",
    "    \n",
    "#Textual Pre-processing\n",
    "testData['text']=testData['text'].str.lower()\n",
    "corpus=testData['text'].values.astype('U')\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=featureNames,ngram_range=(1,2))\n",
    "tX = vectorizer.fit_transform(corpus)\n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "# gender label is transformed \n",
    "y_Test= labelencoder_Y.fit_transform(testData.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   Random Forest (Baseline-1) on Test Dataset\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.4288256227758007\n",
      "Recall       0.5903010033444817\n",
      "Precision    0.4706666666666667\n",
      "F1-Score     0.5237388724035609\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#Testing random forest model on test data\n",
    "y_Pred=clfRF.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'Random Forest (Baseline-1) on Test Dataset') \n",
    "\n",
    "print(np.unique(y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   SVM (Baseline-2) on Test Dataset\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.4679715302491103\n",
      "Recall       0.0\n",
      "Precision    0.0\n",
      "F1-Score     0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\themo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\themo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Testing SVM model on test data\n",
    "y_Pred=clfSVM.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'SVM (Baseline-2) on Test Dataset')\n",
    "# set(y_Pred)\n",
    "# f1_score(y_Test,y_Pred)\n",
    "# print(np.unique(y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts POS tagging for each word of the sentence and add it with the sentence\n",
    "def POSBasedFeatures(data):\n",
    "    print(len(data))\n",
    "    taggedData=[]\n",
    "    for row in data:\n",
    "        \n",
    "        d=''\n",
    "        #print('...')\n",
    "        #print(row)\n",
    "        tokens = word_tokenize(str(row))\n",
    "        #nltk library to extract POS tagging\n",
    "        tagged=nltk.pos_tag(tokens)\n",
    "        \n",
    "        #print(tagged)\n",
    "        if tagged:\n",
    "            for t in tagged:\n",
    "                #print(t)\n",
    "                d=d+ ' '+t[1] +' '+t[0]\n",
    "#                 print (d)\n",
    "            taggedData.append(d)\n",
    "        else:\n",
    "            d=\"NAN\"+ ' '+\"NAN\" +' '+\"NAN\"\n",
    "            taggedData.append(d)\n",
    "        #print(tagged)\n",
    "    print(len(taggedData))\n",
    "    return taggedData\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10113\n",
      "10113\n"
     ]
    }
   ],
   "source": [
    "posData=POSBasedFeatures(data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10113, 23735)\n"
     ]
    }
   ],
   "source": [
    "#making tf-idf vector ngram=(1,2) means unigram and bigram tokens are used. \n",
    "# Rest of the code is same as the one as without applying POS\n",
    "vectorizer = TfidfVectorizer(lowercase=False,ngram_range=(1,2))\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(posData)\n",
    "print(X.shape)\n",
    "# X1 = vectorizer.fit_transform(posData[2827:])\n",
    "# for i in X:\n",
    "#     print(i)\n",
    "featureNames=vectorizer.get_feature_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    " \n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "#Y = labelencoder_Y.fit_transform(data.gender)\n",
    "Y= labelencoder_Y.fit_transform(data.gender)\n",
    "#posdata split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   Random Forest (Baseline-1) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.5590173756740563\n",
      "Recall       0.6128461991750147\n",
      "Precision    0.5606469002695418\n",
      "F1-Score     0.5855855855855856\n"
     ]
    }
   ],
   "source": [
    " \n",
    "clfRF = RandomForestClassifier(n_estimators=100, min_samples_split=4)\n",
    "clfRF.fit(X_train, y_train) \n",
    "y_pred=clfRF.predict(X_test)\n",
    "evaluate(y_test,y_pred,'Random Forest (Baseline-1) on splitted_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   SVM (Baseline-2) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.5011983223487118\n",
      "Recall       0.038892162639952856\n",
      "Precision    0.66\n",
      "F1-Score     0.07345575959933222\n"
     ]
    }
   ],
   "source": [
    "clfSVM=SVC(gamma='auto',kernel='linear', C = 0.05)\n",
    "clfSVM.fit(X_train, y_train) \n",
    "y_pred=clfSVM.predict(X_test)\n",
    "evaluate(y_test,y_pred,'SVM (Baseline-2) on splitted_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124\n",
      "1124\n"
     ]
    }
   ],
   "source": [
    "#Test data WITH POS TAGS-----------\n",
    "\n",
    "posData=POSBasedFeatures(testData['text'])\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=featureNames,ngram_range=(1,2))\n",
    "tX = vectorizer.fit_transform(posData)\n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "#Y = labelencoder_Y.fit_transform(data.gender)\n",
    "y_Test= labelencoder_Y.fit_transform(testData.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   Random Forest (Baseline-1) on Test Dataset\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.18505338078291814\n",
      "Recall       0.0802675585284281\n",
      "Precision    0.11594202898550725\n",
      "F1-Score     0.09486166007905138\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "y_Pred=clfRF.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'Random Forest (Baseline-1) on Test Dataset') \n",
    "\n",
    "print(np.unique(y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   SVM (Baseline-2) on Test Dataset\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.4679715302491103\n",
      "Recall       0.0\n",
      "Precision    0.0\n",
      "F1-Score     0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\themo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\themo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Pred=clfSVM.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'SVM (Baseline-2) on Test Dataset')\n",
    "f1_score(y_Test,y_Pred)\n",
    "# print(np.unique(y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
