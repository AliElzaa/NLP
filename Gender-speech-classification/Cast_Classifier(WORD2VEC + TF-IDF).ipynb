{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library to read input file\n",
    "import pandas as pd\n",
    "#For math operations\n",
    "import numpy as np\n",
    "# Used for splitting training data into validation and training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Used for making TF-IDF vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#used for computing precision_recall_fscore\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#used for computing accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Compute F1-score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Compute Precision \n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#Computes Recall\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# NLTK lib for word tokenization and other pre-processing\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "#Preprocessing libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize,WordNetLemmatizer\n",
    "\n",
    "#regular expression\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>character</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Someone had fun.</td>\n",
       "      <td>SEAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's no problem, honestly. Go on, go and open ...</td>\n",
       "      <td>SHIRLEY</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last night was better than ever. What's all th...</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have you checked the answerphone?  Any calls?</td>\n",
       "      <td>IAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oscar's asleep.</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text character  gender\n",
       "0                                   Someone had fun.      SEAN    male\n",
       "1  It's no problem, honestly. Go on, go and open ...   SHIRLEY  female\n",
       "2  Last night was better than ever. What's all th...       MAX    male\n",
       "3      Have you checked the answerphone?  Any calls?       IAN    male\n",
       "4                                    Oscar's asleep.       MAX    male"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Training dataa\n",
    "data = pd.read_csv('training.csv',header=None, names=['text','character','gender'])\n",
    "\n",
    "data.head()\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRE-PROCESSING\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "#lemmatizes \n",
    "def lem_message(text):\n",
    "    temp=[]\n",
    "    text = text.split()\n",
    "    wl=WordNetLemmatizer()\n",
    "    for i in text:\n",
    "        temp.append(wl.lemmatize(i,pos='v'))\n",
    "    return \" \".join(temp)\n",
    "\n",
    "#this function removes stopwords\n",
    "def remove_stopwords(text,stoplist):\n",
    "    temp=[]\n",
    "#     print(text)\n",
    "#     print (len(text))\n",
    "    text = text.split()\n",
    "    for i in range (len(text)):\n",
    "        if text[i] not in stoplist:\n",
    "            temp.append(text[i])\n",
    "    return \" \".join(temp)\n",
    "\n",
    "import string\n",
    "x = string.punctuation\n",
    "for i in range (data.shape[0]):\n",
    "    data[\"text\"].iloc[i] = re.sub('['+x+']' ,'',str(data[\"text\"].iloc[i])) #thi removes special chars\n",
    "    data[\"text\"].iloc[i] = remove_stopwords(data[\"text\"].iloc[i],stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>character</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Someone fun</td>\n",
       "      <td>SEAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its problem honestly Go go open launderette Leave</td>\n",
       "      <td>SHIRLEY</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last night better ever Whats Anything interesting</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have checked answerphone Any calls</td>\n",
       "      <td>IAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oscars asleep</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text character  gender\n",
       "0                                        Someone fun      SEAN    male\n",
       "1  Its problem honestly Go go open launderette Leave   SHIRLEY  female\n",
       "2  Last night better ever Whats Anything interesting       MAX    male\n",
       "3                 Have checked answerphone Any calls       IAN    male\n",
       "4                                      Oscars asleep       MAX    male"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting reading the data for processing Embeddings\n",
    "corpus = []\n",
    "sentences = []\n",
    "from gensim.models import Word2Vec\n",
    "for i in range (data.shape[0]):\n",
    "    corpus.extend(str(data[\"text\"].iloc[i]).split())\n",
    "    sentences.append(str(data[\"text\"].iloc[i]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5241179, 6239200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a Word2Vec model on the data\n",
    "from gensim.models import Word2Vec\n",
    "model_W2V = Word2Vec(sentences, size=200, window=10, min_count=1) #initilize\n",
    "model_W2V.train(sentences, total_examples=len(set(corpus)),epochs=100) #trains model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BRADLEY', 'CHRISTIAN', 'CLARE', 'GARRY', 'HEATHER', 'IAN', 'JACK',\n",
       "       'JANE', 'MAX', 'MINTY', 'PHIL', 'RONNIE', 'ROXY', 'SEAN',\n",
       "       'SHIRLEY', 'STACEY', 'STEVEN', 'TANYA'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data[\"character\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data [\"vecs\"] = data[\"text\"] #make new column for vecs in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\themo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    sent = data[\"vecs\"].iloc[i]\n",
    "    sent_vec = np.zeros((200,))\n",
    "    for word in sent:\n",
    "        if word in set(model_W2V.wv.index2word): #check if words are present in vocab\n",
    "            sent_vec += model_W2V[word] #adding vectors for words\n",
    "    \n",
    "    data[\"vecs\"].iloc[i] = sent_vec\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>character</th>\n",
       "      <th>gender</th>\n",
       "      <th>vecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Someone fun</td>\n",
       "      <td>SEAN</td>\n",
       "      <td>male</td>\n",
       "      <td>[0.4833850860595703, -0.07849548012018204, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its problem honestly Go go open launderette Leave</td>\n",
       "      <td>SHIRLEY</td>\n",
       "      <td>female</td>\n",
       "      <td>[0.17704612456145696, 0.6082140542566776, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last night better ever Whats Anything interesting</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "      <td>[2.3692171424627304, 0.0736575685441494, -1.71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have checked answerphone Any calls</td>\n",
       "      <td>IAN</td>\n",
       "      <td>male</td>\n",
       "      <td>[1.7213956512132427, 0.31234126165509224, -1.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oscars asleep</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "      <td>[-0.22403573025076184, 0.2623397260904312, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text character  gender  \\\n",
       "0                                        Someone fun      SEAN    male   \n",
       "1  Its problem honestly Go go open launderette Leave   SHIRLEY  female   \n",
       "2  Last night better ever Whats Anything interesting       MAX    male   \n",
       "3                 Have checked answerphone Any calls       IAN    male   \n",
       "4                                      Oscars asleep       MAX    male   \n",
       "\n",
       "                                                vecs  \n",
       "0  [0.4833850860595703, -0.07849548012018204, -0....  \n",
       "1  [0.17704612456145696, 0.6082140542566776, 0.30...  \n",
       "2  [2.3692171424627304, 0.0736575685441494, -1.71...  \n",
       "3  [1.7213956512132427, 0.31234126165509224, -1.3...  \n",
       "4  [-0.22403573025076184, 0.2623397260904312, -0....  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We had shape issues so we stacked pandas into numpy array\n",
    "X_stacked = data[\"vecs\"].iloc[0]\n",
    "for i in range(1,data.shape[0]):\n",
    "    X_stacked = np.vstack((X_stacked,data[\"vecs\"].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10113, 42153)\n"
     ]
    }
   ],
   "source": [
    "#Prepares TF_IDF scores for training data\n",
    "data['text']=data['text'].str.lower()\n",
    "corpus=data['text'].values.astype('U')\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X_tf = vectorizer.fit_transform(corpus) #Tf x value\n",
    "print(X_tf.shape)\n",
    "\n",
    "featureNames=vectorizer.get_feature_names()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data [classA,classB] -> [0,1]\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    " \n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "Y= labelencoder_Y.fit_transform(data.character)\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_stacked, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(y_test,y_pred,algoText='Random Forest (Baseline-1)'):\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('Results of  ',algoText)\n",
    "\n",
    "    print('------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    print('Accuracy    ',accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print('Recall      ',recall_score(y_test, y_pred,average='micro'))\n",
    "    \n",
    "    print('Precision   ',precision_score(y_test,y_pred,average='micro'))\n",
    "\n",
    "    print('F1-Score    ',f1_score(y_test,y_pred,average='micro'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test,y_pred,algoText='Random Forest (Baseline-1)'):\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('Results of  ',algoText)\n",
    "\n",
    "    print('------------------------------------------------------------------')\n",
    "    \n",
    "    print('Accuracy    ',accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision - Recall - F1 scores with different averaging\")\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='micro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6775, 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   Random Forest + Word2Vec (Baseline-1) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.11473936488915518\n",
      "Precision - Recall - F1 scores with different averaging\n",
      "(0.08024587111423123, 0.07218486373617489, 0.06509679105356693, None)\n",
      "(0.11473936488915518, 0.11473936488915518, 0.11473936488915518, None)\n",
      "(0.09282932466744362, 0.11473936488915518, 0.08623735198500111, None)\n"
     ]
    }
   ],
   "source": [
    "#Training RF on Word2Vec\n",
    "clfRF = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "clfRF.fit(X_train, y_train) \n",
    "y_pred=clfRF.predict(X_test)\n",
    "evaluate(y_test,y_pred,'Random Forest + Word2Vec (Baseline-1) on splitted_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   SVM + Word2vec (Baseline-2) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.1318154583582984\n",
      "Precision - Recall - F1 scores with different averaging\n",
      "(0.0307154783718562, 0.05779820959907018, 0.02133567613196795, None)\n",
      "(0.1318154583582984, 0.1318154583582984, 0.1318154583582984, None)\n",
      "(0.048529295525320176, 0.1318154583582984, 0.04304917032479857, None)\n",
      "[ 5  7  8 10 11 14 15 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\themo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Training SVM on Word2vec\n",
    "clfSVM=SVC(gamma='auto',kernel='linear', C = 1)\n",
    "clfSVM.fit(X_train, y_train) \n",
    "y_pred=clfSVM.predict(X_test)\n",
    "evaluate(y_test,y_pred,'SVM + Word2vec (Baseline-2) on splitted_test')\n",
    "\n",
    "print(np.unique(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEst train split TF_IDF SCORES\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   Random Forest + TF-IDF (Baseline-1) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.18184541641701618\n",
      "Precision - Recall - F1 scores with different averaging\n",
      "(0.17788841530751692, 0.14714252747003756, 0.1502546986091796, None)\n",
      "(0.18184541641701618, 0.18184541641701618, 0.18184541641701618, None)\n",
      "(0.1819788138583275, 0.18184541641701618, 0.16893981579716685, None)\n"
     ]
    }
   ],
   "source": [
    "#Training RF with TF_IDF\n",
    "clfRF_TF = RandomForestClassifier(n_estimators=100, min_samples_split=2)\n",
    "clfRF_TF.fit(X_train, y_train) \n",
    "y_pred=clfRF_TF.predict(X_test)\n",
    "evaluate(y_test,y_pred,'Random Forest + TF-IDF (Baseline-1) on splitted_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Results of   SVM + TF-IDF (Baseline-2) on splitted_test\n",
      "------------------------------------------------------------------\n",
      "Accuracy     0.17525464349910125\n",
      "Precision - Recall - F1 scores with different averaging\n",
      "(0.24102439182522697, 0.11452319070047873, 0.10912635788105933, None)\n",
      "(0.17525464349910125, 0.17525464349910125, 0.17525464349910125, None)\n",
      "(0.22599015772971534, 0.17525464349910125, 0.13426261954660396, None)\n"
     ]
    }
   ],
   "source": [
    "#Training SVM with TF_IDF\n",
    "clfSVM_TF=SVC(gamma='auto',kernel='linear', C = 1)\n",
    "clfSVM_TF.fit(X_train, y_train) \n",
    "y_pred=clfSVM_TF.predict(X_test)\n",
    "evaluate(y_test,y_pred,'SVM + TF-IDF (Baseline-2) on splitted_test')\n",
    "\n",
    "# print(np.unique(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5d63219a49bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mtestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testData' is not defined"
     ]
    }
   ],
   "source": [
    "testdata = pd.read_csv('test.csv',header=None, names=['text','character','gender'])\n",
    "\n",
    "testdata.head()\n",
    "#PRE-PROCESSING------------------------------\n",
    "stoplist = stopwords.words('english')\n",
    "#lemmatizes \n",
    "def lem_message(text):\n",
    "    temp=[]\n",
    "    text = text.split()\n",
    "    wl=WordNetLemmatizer()\n",
    "    for i in text:\n",
    "        temp.append(wl.lemmatize(i,pos='v'))\n",
    "    return \" \".join(temp)\n",
    "\n",
    "#this function removes stopwords\n",
    "def remove_stopwords(text,stoplist):\n",
    "    temp=[]\n",
    "#     print(text)\n",
    "#     print (len(text))\n",
    "    text = text.split()\n",
    "    for i in range (len(text)):\n",
    "        if text[i] not in stoplist:\n",
    "            temp.append(text[i])\n",
    "    return \" \".join(temp)\n",
    "\n",
    "import string\n",
    "x = string.punctuation\n",
    "for i in range (testdata.shape[0]):\n",
    "    testdata[\"text\"].iloc[i] = re.sub('['+x+']' ,'',str(testdata[\"text\"].iloc[i])) #thi removes special chars use this only :p for every sentence in train and test\n",
    "    testdata[\"text\"].iloc[i] = lem_message(str(testdata[\"text\"].iloc[i]))\n",
    "    testdata[\"text\"].iloc[i] = remove_stopwords(testdata[\"text\"].iloc[i],stoplist)\n",
    "    \n",
    "#------------------------------------------------\n",
    "\n",
    "testData['text']=testData['text'].str.lower()\n",
    "corpus=testData['text'].values.astype('U')\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=featureNames,ngram_range=(1,2))\n",
    "tX = vectorizer.fit_transform(corpus)\n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "#Y = labelencoder_Y.fit_transform(data.gender)\n",
    "y_Test= labelencoder_Y.fit_transform(testData.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Test\n",
    "y_Pred=clfRF_TF.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'Random Forest + TF-IDF (Baseline-1) on Test Dataset') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Pred=clfSVM_TF.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'SVM +TF-IDF (Baseline-2) on Test Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts POS tagging for each word of the sentence and add it with the sentence\n",
    "def POSBasedFeatures(data):\n",
    "    print(len(data))\n",
    "    taggedData=[]\n",
    "    for row in data:\n",
    "        \n",
    "        d=''\n",
    "        #print('...')\n",
    "        #print(row)\n",
    "        tokens = word_tokenize(str(row))\n",
    "        #nltk library to extract POS tagging\n",
    "        tagged=nltk.pos_tag(tokens)\n",
    "        \n",
    "        #print(tagged)\n",
    "        if tagged:\n",
    "            for t in tagged:\n",
    "                #print(t)\n",
    "                d=d+ ' '+t[1] +' '+t[0]\n",
    "#                 print (d)\n",
    "            taggedData.append(d)\n",
    "        else:\n",
    "            d=\"NAN\"+ ' '+\"NAN\" +' '+\"NAN\"\n",
    "            taggedData.append(d)\n",
    "        #print(tagged)\n",
    "    print(len(taggedData))\n",
    "    return taggedData\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posData=POSBasedFeatures(testdata['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False,ngram_range=(2,2))\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(posData)\n",
    "print(X.shape)\n",
    "\n",
    "featureNames=vectorizer.get_feature_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    " \n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "#Y = labelencoder_Y.fit_transform(data.gender)\n",
    "Y= labelencoder_Y.fit_transform(data.character)\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training RF with TF_IDF + POS\n",
    "\n",
    "clfRF_TF_POS = RandomForestClassifier(n_estimators=100, min_samples_split=4)\n",
    "clfRF_TF_POS.fit(X_train, y_train) \n",
    "y_pred=clfRF_TF_POS.predict(X_test)\n",
    "evaluate(y_test,y_pred,'Random Forest + POS + TF-IDF (Baseline-1) on splitted_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training SVM with TF_IDF with PSO\n",
    "\n",
    "clfSVM_TF_POS=SVC(gamma='auto',kernel='linear', C = 0.05)\n",
    "clfSVM_TF_POS.fit(X_train, y_train) \n",
    "y_pred=clfSVM_TF_POS.predict(X_test)\n",
    "evaluate(y_test,y_pred,'SVM + POS + TF-IDF (Baseline-2) on splitted_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Test data\n",
    "\n",
    "posData=POSBasedFeatures(testData['text'])\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=featureNames,ngram_range=(2,2))\n",
    "tX = vectorizer.fit_transform(posData)\n",
    "labelencoder_Y = LabelEncoder()\n",
    "\n",
    "#Y = labelencoder_Y.fit_transform(data.gender)\n",
    "y_Test= labelencoder_Y.fit_transform(testData.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Pred=clfRF_TF_POS.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'Random Forest + POS + TF-IDF (Baseline-1) on Test Dataset') \n",
    "\n",
    "print(np.unique(y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Pred=clfSVM_TF_POS.predict(tX)\n",
    "evaluate(y_Test,y_Pred,'SVM + POS + TF-IDF (Baseline-2) on Test Dataset')\n",
    "\n",
    "print(np.unique(y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
